<?xml version="1.0" encoding="ISO-8859-1" standalone="no"?>
<!DOCTYPE MAN SYSTEM "file://C:\Cygwin\scilab-4.1\man/manrev.dtd">
<MAN>
  <LANGUAGE>eng</LANGUAGE>
  <TITLE>optim_kelley_gradproj</TITLE>
  <TYPE>Scilab Function  </TYPE>
  <DATE>12-Jan-2007</DATE>
  <SHORT_DESCRIPTION name="optim_kelley_gradproj"> gradient projection with Armijo rule, simple linesearch </SHORT_DESCRIPTION>

  <CALLING_SEQUENCE>
  <CALLING_SEQUENCE_ITEM>[x,histout,costdata] = optim_kelley_gradproj(x0,f,up,low,tol,maxit)</CALLING_SEQUENCE_ITEM>
  </CALLING_SEQUENCE>

  <PARAM>
  <PARAM_INDENT>

    <PARAM_ITEM>
    <PARAM_NAME>x0</PARAM_NAME>
    <PARAM_DESCRIPTION>
       <SP>
       : initial iterate
       </SP>
    </PARAM_DESCRIPTION>
    </PARAM_ITEM>

    <PARAM_ITEM>
    <PARAM_NAME>f</PARAM_NAME>
    <PARAM_DESCRIPTION>
       <SP>
       : objective function, the calling sequence for f should be [fout,gout]=f(x) where fout=f(x) is a scalar and gout = grad f(x) is a COLUMN vector
       </SP>
    </PARAM_DESCRIPTION>
    </PARAM_ITEM>

    <PARAM_ITEM>
    <PARAM_NAME>up</PARAM_NAME>
    <PARAM_DESCRIPTION>
       <SP>
       : vector of upper bounds
       </SP>
    </PARAM_DESCRIPTION>
    </PARAM_ITEM>

    <PARAM_ITEM>
    <PARAM_NAME>low</PARAM_NAME>
    <PARAM_DESCRIPTION>
       <SP>
       : vector of lower bounds
       </SP>
    </PARAM_DESCRIPTION>
    </PARAM_ITEM>

    <PARAM_ITEM>
    <PARAM_NAME>tol</PARAM_NAME>
    <PARAM_DESCRIPTION>
       <SP>
       : termination criterion norm(grad) < tol optional, default = 1.d-6
       </SP>
    </PARAM_DESCRIPTION>
    </PARAM_ITEM>

    <PARAM_ITEM>
    <PARAM_NAME>maxit</PARAM_NAME>
    <PARAM_DESCRIPTION>
       <SP>
       : maximum iterations (optional) default = 1000
       </SP>
    </PARAM_DESCRIPTION>
    </PARAM_ITEM>

    <PARAM_ITEM>
    <PARAM_NAME>x</PARAM_NAME>
    <PARAM_DESCRIPTION>
       <SP>
       : solution
       </SP>
    </PARAM_DESCRIPTION>
    </PARAM_ITEM>

    <PARAM_ITEM>
    <PARAM_NAME>histout</PARAM_NAME>
    <PARAM_DESCRIPTION>
       <SP>
       : iteration history - Each row of histout is [norm(grad), f, number of step length reductions, iteration count, relative size of active set]
       </SP>
    </PARAM_DESCRIPTION>
    </PARAM_ITEM>

    <PARAM_ITEM>
    <PARAM_NAME>costdata</PARAM_NAME>
    <PARAM_DESCRIPTION>
       <SP>
       : costdata = [num f, num grad, num hess] (for steep, num hess=0)
       </SP>
    </PARAM_DESCRIPTION>
    </PARAM_ITEM>
  </PARAM_INDENT>
  </PARAM>
 
  <DESCRIPTION>
     <DESCRIPTION_INDENT>
     <DESCRIPTION_ITEM>
     <P>
      gradient projection with Armijo rule, simple linesearch 
     </P>
     </DESCRIPTION_ITEM>
     </DESCRIPTION_INDENT>
  </DESCRIPTION>

  <EXAMPLE><![CDATA[
  function Res = get_min_bound_rosenbrock()
  Res = [-2 -2]';
  endfunction
  function Res = get_max_bound_rosenbrock()
  Res = [2 2]';
  endfunction
  function Res = get_opti_rosenbrock()
  Res = [1 1]';
  endfunction
  function y = rosenbrock(x)
  y = 100*(x(2)-x(1)^2)^2+(1-x(1))^2;
  endfunction
  MaxIt     = 1000;
  Tol       = 1e-6;
  GradTol   = 1e-12;

  Min = get_min_bound_rosenbrock();
  Max = get_max_bound_rosenbrock();

  //
  // Display the cost function
  //

  clf();

  x1 = Min(1):(Max(1)-Min(1))/100:Max(1);
  x2 = Min(2):(Max(2)-Min(2))/100:Max(2);
  for i=1:length(x1)
    for j=1:length(x2)
      z(i,j) = functoopt([x1(i) x2(j)]);
    end
  end
  xset('fpf',' ');
  contour(x1, x2, z, 20);

  function [f, g] = f_optim(x)
  f = functoopt(x);
  g = derivative(functoopt, x); g = g'; // ??
  endfunction

  function [f, g, jac] = f_optim_2(x)
  f = functoopt(x);
  [g, jac] = derivative(functoopt, x); g = g'; jac = jac';// ??
  endfunction

  x0 = [-1.1; 1];

  xtitle(Title + ' function - optim_kelley_gradproj','x1','x2');

  printf('optim_kelley_gradproj:\n');
  printf('gradient projection with Armijo rule, simple linesearch\n');

  xset('fpf',' ');
  contour(x1, x2, z, 20);

  plot(x0(1), x0(2), 'ro');

  [x_opt, histout, costdata] = optim_kelley_gradproj(x0, f_optim, Max, Min, Tol, MaxIt);

  plot(x_opt(1), x_opt(2), 'go');

  printf('optim_kelley_gradproj: Starting point x0:'); disp(x0);
  printf('optim_kelley_gradproj: Final point x_opt:'); disp(x_opt);
  printf('optim_kelley_gradproj: Initial fobj = %f - Final fobj = %f\n', functoopt(x0), functoopt(x_opt));
  ]]></EXAMPLE>

  <SEE_ALSO>
    <SEE_ALSO_ITEM> <LINK> optim_kelley_hooke </LINK> </SEE_ALSO_ITEM>
    <SEE_ALSO_ITEM> <LINK> optim_kelley_steep </LINK> </SEE_ALSO_ITEM>
  </SEE_ALSO>

  <AUTHORS>
    <AUTHORS_ITEM label='Kelley'>
    C. T. Kelley (tim_kelley@ncsu.edu)
    </AUTHORS_ITEM>
  </AUTHORS>

  <BIBLIO>
    <SP>
    C. T. Kelley, "Iterative Methods for Optimization", SIAM, Philadelphia , 1999, Frontiers in Applied Mathematics, 18 
    </SP>
  </BIBLIO>
</MAN>
